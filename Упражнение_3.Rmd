---
title: 'Упражнение 3'
author: "Салимова Э.И."
date: '15 марта 2018 г '
output: word_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
### Практика 3
Модели: логистическая регрессия, QDA.

Данные: 	Glass{mlbench} – химический состав разных типов стекла. 

Пакеты:

```{r}
library('mlbench')
library('GGally')
library('MASS')
```

Зададим ядро генератора случайных чисел и объём обучающей выборки

```{r}
my.seed <- 234
train.percent <- 0.75
options("ggmatrix.progress.bar" = FALSE) 
data(Glass)
df <- Glass
df$Type <- as.numeric(df$Type)
for (i in 1:214){
  if(df[i, 'Type'] != 1){
   df[i, 'Type'] = 0}
}

```

### Графики разброса
```{r}
ggp <- ggpairs(Glass)
print(ggp, progress = FALSE)
```

Отбираем наблюдения в обучающую выборку

```{r}
set.seed(my.seed) 
inTrain <- sample(seq_along(Glass$Type), 
                  nrow(Glass)*train.percent) 
df <- df[inTrain, ] 
# фактические значения на обучающей выборке
Факт <- df$Type

```

### Логистическая регрессия

```{r}
  utils::data(Glass, package = "mlbench")
  model.logit <- glm(Type ~ Na + Mg + Al + Si + K + Ca + Ba + Fe, data = df, family = 'binomial')
  summary(model.logit)
```

Некоторые регрессоры, входящие в модель, незначимы, исключаем их:

```{r}
  model.logit <- glm(Type ~ Mg , data = df, family = 'binomial')
  summary(model.logit)
```

Параметры модели логистической регрессии значимы

```{r}
# прогноз: вероятности принадлежности классу 'Yes' (дефолт)
p.logit <- predict(model.logit, df, type = 'response')
Прогноз <- factor(ifelse(p.logit > 0.5, 2, 1),
                  levels = c(1, 2),
                  labels = c('No', 'Yes'))
# матрица неточностей
conf.m <- table(Факт, Прогноз)
conf.m
```

Вектор p.logit состоит из вероятностей принадлежности наблюдений к классам, а не из меток этих классов. Поэтому для прогноза нужно сделать разделение на два класса вручную, используя какую-то границу отсечения. В данном случае это 0.5 – значение по умолчанию. 

```{r}
# чувствительность
conf.m[2, 2] / sum(conf.m[2, ])
# специфичность
conf.m[1, 1] / sum(conf.m[1, ])
# верность
sum(diag(conf.m)) / sum(conf.m)

```

### QDA

```{r}
#QDA
model.qda <- qda(Type ~ Na + Mg + Al + Si + K + Ca + Ba + Fe, data = df[inTrain, ])
model.qda
# прогноз: вероятности принадлежности классу 'Yes' (дефолт) 
p.qda <- predict(model.qda, df, type = 'response') 
Прогноз <- factor(ifelse(p.qda$posterior[, '1'] > 0.5, 
                         2, 1), 
                  levels = c(1, 2), 
                  labels = c('No', 'Yes')) 

# матрица неточностей 
conf.m <- table(Факт, Прогноз) 
conf.m 
```

```{r}
# чувствительность
conf.m[2, 2] / sum(conf.m[2, ])

# специфичность
conf.m[1, 1] / sum(conf.m[1, ])

# верность
sum(diag(conf.m)) / sum(conf.m)

```

Разделяющая граница квадратичного дисперсионного анализа нелинейна, поэтому коэффициентов в отчёте мы не видим. Чувсивительность чуть хуже, чем у логистичесокй регрессии.

Очевидно, такая ситуация с чувствительностью не может нас устраивать, поскольку высокое значение верности модели (accuracy) обусловлено исключительно большой долей одного из классов в выборке. В такой ситуации надо пожертвовать небольшой частью специфичности, чтобы подтянуть чувствительность. Сделаем это, изменив границу отсечения классов.

### ROC-кривая. Сравнение качества прогноза сравниваемых моделей на обучающей выборке.

Для начала построим график совместного изменения чувствительности и специфичности с изменением вероятности отсечения от 0 до 1 – ROC-кривую.
```{r}
# ROC-кривая =========================================================== 
x <- NULL # для (1 - SPC) 
y <- NULL # для TPR 
x1 <- NULL 
y1 <- NULL 
# заготовка под матрицу неточностей 
tbl <- as.data.frame(matrix(rep(0, 4), 2, 2)) 
rownames(tbl) <- c('fact.No', 'fact.Yes') 
colnames(tbl) <- c('predict.No', 'predict.Yes') 
# вектор вероятностей для перебора 
p.vector <- seq(0, 1, length = 501) 
# цикл по вероятностям отсечения 
for (p in p.vector){ 
  # прогноз 
  Прогноз <- factor(ifelse(p.qda$posterior[, '1'] > p, 
                           2, 1), 
                    levels = c(1, 2), 
                    labels = c('0', '1')) 
  
  # фрейм со сравнением факта и прогноза 
  df.compare <- data.frame(Факт = Факт, Прогноз = Прогноз) 
  
  # заполняем матрицу неточностей 
  tbl[1, 1] <- nrow(df.compare[df.compare$Факт == '0' & df.compare$Прогноз == '0', ]) 
  tbl[2, 2] <- nrow(df.compare[df.compare$Факт == '1' & df.compare$Прогноз == '1', ]) 
  tbl[1, 2] <- nrow(df.compare[df.compare$Факт == '0' & df.compare$Прогноз == '1', ]) 
  tbl[2, 1] <- nrow(df.compare[df.compare$Факт == '1' & df.compare$Прогноз == '0', ]) 
  
  # считаем характеристики 
  TPR <- tbl[2, 2] / sum(tbl[2, 2] + tbl[2, 1]) 
  y <- c(y, TPR) 
  SPC <- tbl[1, 1] / sum(tbl[1, 1] + tbl[1, 2]) 
  x <- c(x, 1 - SPC) 
} 
for (p in p.vector){ 
  # прогноз 
  Прогноз1 <- factor(ifelse(p.logit > p, 
                            2, 1), 
                     levels = c(1, 2), 
                     labels = c('0', '1')) 
  
  # фрейм со сравнением факта и прогноза 
  df.compare <- data.frame(Факт = Факт, Прогноз1 = Прогноз1) 
  
  #заполняем матрицу неточностей 
  tbl[1, 1] <- nrow(df.compare[df.compare$Факт == '0' & df.compare$Прогноз == '0', ]) 
  tbl[2, 2] <- nrow(df.compare[df.compare$Факт == '1' & df.compare$Прогноз == '1', ]) 
  tbl[1, 2] <- nrow(df.compare[df.compare$Факт == '0' & df.compare$Прогноз == '1', ]) 
  tbl[2, 1] <- nrow(df.compare[df.compare$Факт == '1' & df.compare$Прогноз == '0', ])
  
  # считаем характеристики 
  TPR <- tbl[2, 2] / sum(tbl[2, 2] + tbl[2, 1]) 
  y1 <- c(y1, TPR) 
  SPC <- tbl[1, 1] / sum(tbl[1, 1] + tbl[1, 2]) 
  x1 <- c(x1, 1 - SPC) 
} 

# строим ROC-кривую 
par(mar = c(5, 5, 1, 1)) 
# кривая 
plot(x, y, main = 'Обучающая выборка',
     type = 'l', col = 'blue', lwd = 2, #qda
     xlab = '(1 - SPC)', ylab = 'TPR', 
     xlim = c(0, 1), ylim = c(0, 1)) 
lines(x1, y1, type = 'l', col = 'red', lwd = 2, #logit
      xlab = '(1 - SPC)', ylab = 'TPR', 
      xlim = c(0, 1), ylim = c(0, 1)) 
# прямая случайного классификатора 
abline(a = 0, b = 1, lty = 3, lwd = 2) 
# точка для вероятности 0.5 
points(x[p.vector == 0.5], y[p.vector == 0.5], pch = 16) 
text(x[p.vector == 0.5], y[p.vector == 0.5], 'p = 0.5(qda)', pos = 4) 
# точка для вероятности 0.2 
points(x[p.vector == 0.2], y[p.vector == 0.2], pch = 16) 
text(x[p.vector == 0.2], y[p.vector == 0.2], 'p = 0.2(qda)', pos = 4) 

# точка для вероятности 0.5 
points(x1[p.vector == 0.5], y1[p.vector == 0.5], pch = 16) 
text(x1[p.vector == 0.5], y1[p.vector == 0.5], 'p = 0.5(logit)', pos = 4) 
# точка для вероятности 0.2 
points(x1[p.vector == 0.2], y1[p.vector == 0.2], pch = 16) 
text(x1[p.vector == 0.2], y1[p.vector == 0.2], 'p = 0.2(logit)', pos = 4) 

```

### ROC-кривая. Сравнение качества прогноза сравниваемых моделей на тестовой выборке.

```{r}
df <- Glass[-inTrain, ]
df <- Glass
df$Type <- as.numeric(df$Type)
for (i in 1:214){
  if(df[i, 'Type'] != 1){
    df[i, 'Type'] = 0}
}
# фактические значения на обучающей выборке 
Факт <- df$Type

# Логистическая регрессия
model.logit <- glm(Type ~ Na + Mg + Al + Si + K + Ca + Ba + Fe, data = df, family = 'binomial')
summary(model.logit)
# исключаем незначимые
model.logit <- glm(Type ~ Mg , data = df, family = 'binomial')
summary(model.logit)

# прогноз: вероятности принадлежности классу 'Yes' (дефолт)
p.logit <- predict(model.logit, df, type = 'response')
Прогноз <- factor(ifelse(p.logit > 0.5, 2, 1),
                  levels = c(1, 2),
                  labels = c('No', 'Yes'))


# QDA =========================================================================
model.qda <- qda(Type ~ Na + Mg + Al + Si + K + Ca + Ba + Fe, data = df)
model.qda

# прогноз: вероятности принадлежности классу 'Yes' (дефолт)
p.qda <- predict(model.qda, df, type = 'response')
Прогноз <- factor(ifelse(p.qda$posterior[, '1'] > 0.5, 
                         2, 1),
                  levels = c(1, 2),
                  labels = c('No', 'Yes'))

# ROC-кривая =========================================================== 

# считаем 1-SPC и TPR для всех вариантов границы отсечения 
x <- NULL # для (1 - SPC) 
y <- NULL # для TPR 
x1 <- NULL 
y1 <- NULL 
# заготовка под матрицу неточностей 
tbl <- as.data.frame(matrix(rep(0, 4), 2, 2)) 
rownames(tbl) <- c('fact.No', 'fact.Yes') 
colnames(tbl) <- c('predict.No', 'predict.Yes') 
# вектор вероятностей для перебора 
p.vector <- seq(0, 1, length = 501) 
# цикл по вероятностям отсечения 
for (p in p.vector){ 
  # прогноз 
  Прогноз <- factor(ifelse(p.qda$posterior[, '1'] > p, 
                           2, 1), 
                    levels = c(1, 2), 
                    labels = c('0', '1')) 
  
  # фрейм со сравнением факта и прогноза 
  df.compare <- data.frame(Факт = Факт, Прогноз = Прогноз) 
  
  # заполняем матрицу неточностей 
  tbl[1, 1] <- nrow(df.compare[df.compare$Факт == '0' & df.compare$Прогноз == '0', ]) 
  tbl[2, 2] <- nrow(df.compare[df.compare$Факт == '1' & df.compare$Прогноз == '1', ]) 
  tbl[1, 2] <- nrow(df.compare[df.compare$Факт == '0' & df.compare$Прогноз == '1', ]) 
  tbl[2, 1] <- nrow(df.compare[df.compare$Факт == '1' & df.compare$Прогноз == '0', ]) 
  
  # считаем характеристики 
  TPR <- tbl[2, 2] / sum(tbl[2, 2] + tbl[2, 1]) 
  y <- c(y, TPR) 
  SPC <- tbl[1, 1] / sum(tbl[1, 1] + tbl[1, 2]) 
  x <- c(x, 1 - SPC) 
} 
for (p in p.vector){ 
  # прогноз 
  Прогноз1 <- factor(ifelse(p.logit > p, 
                            2, 1), 
                     levels = c(1, 2), 
                     labels = c('0', '1')) 
  
  # фрейм со сравнением факта и прогноза 
  df.compare <- data.frame(Факт = Факт, Прогноз1 = Прогноз1) 
  
  #заполняем матрицу неточностей 
  tbl[1, 1] <- nrow(df.compare[df.compare$Факт == '0' & df.compare$Прогноз == '0', ]) 
  tbl[2, 2] <- nrow(df.compare[df.compare$Факт == '1' & df.compare$Прогноз == '1', ]) 
  tbl[1, 2] <- nrow(df.compare[df.compare$Факт == '0' & df.compare$Прогноз == '1', ]) 
  tbl[2, 1] <- nrow(df.compare[df.compare$Факт == '1' & df.compare$Прогноз == '0', ])
  
  # считаем характеристики 
  TPR <- tbl[2, 2] / sum(tbl[2, 2] + tbl[2, 1]) 
  y1 <- c(y1, TPR) 
  SPC <- tbl[1, 1] / sum(tbl[1, 1] + tbl[1, 2]) 
  x1 <- c(x1, 1 - SPC) 
} 

# строим ROC-кривую 
par(mar = c(5, 5, 1, 1)) 
# кривая 
plot(x, y, main = 'Тестовая выборка',
     type = 'l', col = 'blue', lwd = 2, #qda
     xlab = '(1 - SPC)', ylab = 'TPR', 
     xlim = c(0, 1), ylim = c(0, 1)) 
lines(x1, y1, type = 'l', col = 'red', lwd = 2, #logit
      xlab = '(1 - SPC)', ylab = 'TPR', 
      xlim = c(0, 1), ylim = c(0, 1)) 
# прямая случайного классификатора 
abline(a = 0, b = 1, lty = 3, lwd = 2) 
# точка для вероятности 0.5 
points(x[p.vector == 0.5], y[p.vector == 0.5], pch = 16) 
text(x[p.vector == 0.5], y[p.vector == 0.5], 'p = 0.5(qda)', pos = 4) 
# точка для вероятности 0.2 
points(x[p.vector == 0.2], y[p.vector == 0.2], pch = 16) 
text(x[p.vector == 0.2], y[p.vector == 0.2], 'p = 0.2(qda)', pos = 4) 

# точка для вероятности 0.5 
points(x1[p.vector == 0.5], y1[p.vector == 0.5], pch = 16) 
text(x1[p.vector == 0.5], y1[p.vector == 0.5], 'p = 0.5(logit)', pos = 4) 
# точка для вероятности 0.2 
points(x1[p.vector == 0.2], y1[p.vector == 0.2], pch = 16) 
text(x1[p.vector == 0.2], y1[p.vector == 0.2], 'p = 0.2(logit)', pos = 4) 
```

ROC-кривые для логистической регрессии и QDA заметно различаются, и для решения поставленной задачи лучше использовать QDA (т.к. ее график лежит выше).

